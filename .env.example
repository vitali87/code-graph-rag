# Model Provider Configuration

# Example 1: All Ollama (local)
# ORCHESTRATOR_PROVIDER=ollama
# ORCHESTRATOR_MODEL=llama3.2
# ORCHESTRATOR_ENDPOINT=http://localhost:11434/v1

# CYPHER_PROVIDER=ollama
# CYPHER_MODEL=codellama
# CYPHER_ENDPOINT=http://localhost:11434/v1

# Example 2: All OpenAI
# ORCHESTRATOR_PROVIDER=openai
# ORCHESTRATOR_MODEL=gpt-4o
# ORCHESTRATOR_API_KEY=sk-your-openai-key

# CYPHER_PROVIDER=openai
# CYPHER_MODEL=gpt-4o-mini
# CYPHER_API_KEY=sk-your-openai-key

# Example 3: All Google (AI Studio)
# ORCHESTRATOR_PROVIDER=google
# ORCHESTRATOR_MODEL=gemini-2.5-pro
# ORCHESTRATOR_API_KEY=your-google-api-key

# CYPHER_PROVIDER=google
# CYPHER_MODEL=gemini-2.5-flash
# CYPHER_API_KEY=your-google-api-key

# Example 4: Google Vertex AI
# ORCHESTRATOR_PROVIDER=google
# ORCHESTRATOR_MODEL=gemini-2.5-pro
# ORCHESTRATOR_PROJECT_ID=your-gcp-project-id
# ORCHESTRATOR_REGION=us-central1
# ORCHESTRATOR_PROVIDER_TYPE=vertex
# ORCHESTRATOR_SERVICE_ACCOUNT_FILE=/path/to/service-account.json

# CYPHER_PROVIDER=google
# CYPHER_MODEL=gemini-2.5-flash
# CYPHER_PROJECT_ID=your-gcp-project-id
# CYPHER_REGION=us-central1
# CYPHER_PROVIDER_TYPE=vertex
# CYPHER_SERVICE_ACCOUNT_FILE=/path/to/service-account.json

# Example 5: Mixed - Google orchestrator + Ollama cypher
# ORCHESTRATOR_PROVIDER=google
# ORCHESTRATOR_MODEL=gemini-2.5-pro
# ORCHESTRATOR_API_KEY=your-google-api-key

# CYPHER_PROVIDER=ollama
# CYPHER_MODEL=codellama
# CYPHER_ENDPOINT=http://localhost:11434/v1

# Example 6: Mixed - OpenAI orchestrator + Google cypher
# ORCHESTRATOR_PROVIDER=openai
# ORCHESTRATOR_MODEL=gpt-4o
# ORCHESTRATOR_API_KEY=sk-your-openai-key

# CYPHER_PROVIDER=google
# CYPHER_MODEL=gemini-2.5-flash
# CYPHER_API_KEY=your-google-api-key

# Example 7: Anthropic Claude (Direct API)
# ORCHESTRATOR_PROVIDER=anthropic
# ORCHESTRATOR_MODEL=claude-sonnet-4.5-20250929
# ORCHESTRATOR_API_KEY=sk-ant-your-key

# CYPHER_PROVIDER=anthropic
# CYPHER_MODEL=claude-haiku-4-20250514
# CYPHER_API_KEY=sk-ant-your-key

# Example 8: Anthropic Claude (via Portkey proxy)
# ORCHESTRATOR_PROVIDER=anthropic
# ORCHESTRATOR_MODEL=claude-sonnet-4.5-20250929
# ORCHESTRATOR_ENDPOINT=https://your-portkey-gateway.com
# ORCHESTRATOR_CUSTOM_HEADERS="x-portkey-api-key: pk-xxx\nx-portkey-config: pc-xxx"

# CYPHER_PROVIDER=anthropic
# CYPHER_MODEL=claude-haiku-4-20250514
# CYPHER_ENDPOINT=https://your-portkey-gateway.com
# CYPHER_CUSTOM_HEADERS="x-portkey-api-key: pk-xxx\nx-portkey-config: pc-xxx"

# Example 9: Anthropic Claude (uses ~/.claude/settings.json automatically)
# Just set provider and model - will auto-detect from Claude Code settings
# ORCHESTRATOR_PROVIDER=anthropic
# ORCHESTRATOR_MODEL=claude-sonnet-4.5-20250929

# CYPHER_PROVIDER=anthropic
# CYPHER_MODEL=claude-haiku-4-20250514

# Thinking budget for reasoning models (optional)
# ORCHESTRATOR_THINKING_BUDGET=10000
# CYPHER_THINKING_BUDGET=5000

# Memgraph settings
MEMGRAPH_HOST=localhost
MEMGRAPH_PORT=7687
MEMGRAPH_HTTP_PORT=7444
# Memgraph authentication credentials
# Leave MEMGRAPH_USERNAME empty (or omit it) if your Memgraph instance doesn't require authentication
# If authentication is enabled, provide both username and password
# Common defaults: username=neo4j, password=password (or your custom credentials)
MEMGRAPH_USERNAME=
MEMGRAPH_PASSWORD=
LAB_PORT=3000
MEMGRAPH_BATCH_SIZE=1000

# Repository settings
TARGET_REPO_PATH=.

# Ollama base URL (without /v1 suffix)
OLLAMA_BASE_URL=http://localhost:11434
